# Dependencies:
# - numpy: Used for generating random data arrays, which is essential for simulating datasets in data science and machine learning.
# - matplotlib: Used for visualizing data distributions through histograms, which helps in understanding the shape and spread of the data.

import numpy as np
import matplotlib.pyplot as plt

# Definition: Data Distribution
# Data distribution refers to how data points are spread across different values or ranges.
# In machine learning, understanding data distribution is critical for:
# - Detecting outliers and anomalies
# - Choosing appropriate preprocessing techniques and models
# - Validating assumptions (e.g., normality) that many algorithms depend on
# - Informing feature engineering and selection

# Example 1: Small Dataset
# Generate an array of 250 random floats between 0 and 5 using NumPy's uniform distribution.
x_small = np.random.uniform(0.0, 5.0, 250)

# Visualize the small dataset with a histogram (5 bins)
# Each bar shows how many values fall within a certain range.
plt.hist(x_small, bins=5)
plt.title('Histogram of 250 Random Floats Between 0 and 5')
plt.xlabel('Value Range')
plt.ylabel('Frequency')
plt.show()

# Example 2: Large Dataset
# Generate a much larger array of 100,000 random floats between 0 and 5.
x_large = np.random.uniform(0.0, 5.0, 100000)

# Visualize the large dataset with a histogram (100 bins)
# More bins provide a more detailed view of the distribution.
plt.hist(x_large, bins=100)
plt.title('Histogram of 100,000 Random Floats Between 0 and 5')
plt.xlabel('Value Range')
plt.ylabel('Frequency')
plt.show()

# Why This Is Important for Machine Learning:
# - Visualizing data distributions helps you understand your dataset before modeling.
# - It guides decisions on data cleaning, transformation, and algorithm selection.
# - Ensures that the data meets the assumptions required by many machine learning models.
